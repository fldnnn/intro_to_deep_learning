# -*- coding: utf-8 -*-
"""CNN_face_expression_recognition1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SGRvqnekbMtSdy65AL_yOej4uV8LIUTG
"""

from google.colab import drive
drive.mount('/content/drive/')

import os
os.chdir('/content/drive/My Drive/Evrisimli_Sinir_Aglari/Duygu_Tanima/')

!ls

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline

import keras
from keras.models import Sequential, Model, model_from_json
from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization
from keras.utils import np_utils
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint

root = '/content/drive/My Drive/Evrisimli_Sinir_Aglari/Duygu_Tanima/'

data = pd.read_csv(root + 'data/fer2013/fer2013.csv')
data.shape

data.head()

data["Usage"].value_counts()

np.unique(data["Usage"].values.ravel()) 

print('Eğitim verisetindeki örnek sayısı: %d'%(len(data[data.Usage == "Training"])))

train_data = data[data.Usage == "Training"] #sadece eğitim örneklerini train_data değişkenine al

#eğitim örneklerinin piksel değerleri bize tablo halinde yan yana verildiği için boşluklardan parse ederek liste olarak değişkene al
train_pixels = train_data.pixels.str.split(" ").tolist() 

train_pixels = pd.DataFrame(train_pixels, dtype=int)
train_images = train_pixels.values
train_images = train_images.astype(np.float)

print(train_images)

print(train_images.shape)

#Resmi 48x48 px şeklinde göstermek için bir fonksiyon tanımlanir
def show(img):
    show_image = img.reshape(48,48)
    
    plt.axis('off')
    plt.imshow(show_image, cmap='gray')

show(train_images[22])

train_labels_flat = train_data["emotion"].values.ravel() #labellardan emotiondaki kac tane satır var yukardaki tablo
train_labels_count = np.unique(train_labels_flat).shape[0]
print('Farklı yüz ifadelerinin sayısı: %d'%train_labels_count)

def dense_to_one_hot(labels_dense, num_classes):
    num_labels = labels_dense.shape[0]
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
    return labels_one_hot

y_train = dense_to_one_hot(train_labels_flat, train_labels_count)
y_train = y_train.astype(np.uint8)

print(y_train.shape) #her bir göruntuden 7 tane sınıf olacak

np.unique(data["Usage"].values.ravel()) #test datası on ısleme

print('Test verisetindeki örnek sayısı: %d'%(len(data[data.Usage == "PublicTest"])))

test_data = data[data.Usage == "PublicTest"] #her bir satırdaki piksel degerlerinin cekılmesi public icindeki. 2304
test_pixels = test_data.pixels.str.split(" ").tolist() 

test_pixels = pd.DataFrame(test_pixels, dtype=int)
test_images = test_pixels.values
test_images = test_images.astype(np.float)

print(test_images.shape)

show(test_images[5])

test_labels_flat = test_data["emotion"].values.ravel()
test_labels_count = np.unique(test_labels_flat).shape[0]

y_test = dense_to_one_hot(test_labels_flat, test_labels_count)
y_test = y_test.astype(np.uint8)


print(y_test.shape)

#test verisetinden örneklerden bir kaçını toplu halde gösterimi

plt.figure(0, figsize=(12,6))
for i in range(1, 13):
    plt.subplot(3,4,i)
    plt.axis('off')
    
    image = test_images[i].reshape(48,48)
    plt.imshow(image, cmap="gray")

plt.tight_layout()
plt.show()

model = Sequential()

model.add(Conv2D(64, 3, data_format="channels_last", kernel_initializer="he_normal", input_shape=(48, 48, 1))) #3tane filtre var
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(64, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.6)) #%60 unutma islemi(droput noron silme)

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.6))

model.add(Flatten()) #katmanlar vektor halıne getirlir
model.add(Dense(128)) #baglantı ıslemlerı
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(Dropout(0.6))

model.add(Dense(7))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

x_train = train_images.reshape(-1, 48, 48, 1) #egıtım ve test kumelerının eleman sayısı, yukseklık ve genıslık, kanal sayısı bılgılerının yazdırılması
x_test = test_images.reshape(-1, 48, 48, 1)

print("Train:", x_train.shape)
print("Test:", x_test.shape)

print("Train:", y_train.shape) #egitim ve test kumelerinin eleman ve duygu sınıf sayısı
print("Test:", y_test.shape)

# en başarılı ağırlıkları kaydet
checkpointer = ModelCheckpoint(filepath=root + 'data/face_model.h5', verbose=1, save_best_only=True) #dosya kaydetme

epochs = 10
batchSize = 100 

# modeli çalıştır
hist = model.fit(x_train, y_train, #modelin calıstırılacagı kısım yazılır
                 epochs=epochs,
                 shuffle=True, #rastgele
                 batch_size=batchSize, 
                 validation_data=(x_test, y_test), #testten secerek validasyon yapılır
                 callbacks=[checkpointer], verbose=2) #checkpoıntle validasyonun ıyı oldugu degerleri her bir epochda daha ıyı olan durum kaydedılır

# save model to json
model_json = model.to_json() #json uzatısıyla kaydedılır
with open(root + "data/face_model.json", "w") as json_file:
    json_file.write(model_json)

plt.figure(figsize=(14,3)) #egıtım sonucu elde edılen egıtım ve validation gecerleme sonuclarının grafıksel olarak ıfade edılıp yazdırılması
plt.subplot(1, 2, 1)
plt.suptitle('Eğitim', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.plot(hist.history['loss'], color='b', label='Training Loss')
plt.plot(hist.history['val_loss'], color='r', label='Validation Loss')
plt.legend(loc='upper right')

plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.plot(hist.history['val_accuracy'], color='b', label='Training Accuracy')
plt.plot(hist.history['val_accuracy'], color='r', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

test = data[["emotion", "pixels"]][data["Usage"] == "PrivateTest"] #Kaggle submit edecek gibi PrivateTest örnekleri ile test edilmesi
test["pixels"] = test["pixels"].apply(lambda im: np.fromstring(im, sep=' '))
test.head()

x_test_private = np.vstack(test["pixels"].values)
y_test_private = np.array(test["emotion"])

x_test_private = x_test_private.reshape(-1, 48, 48, 1) #dizilerin arraylerin çekilmesi 48 48 genıslık yukselık bır kanal boyutuna sahıp kac tane elemanı oldugunu yazdır 3589 tane
y_test_private = np_utils.to_categorical(y_test_private)
x_test_private.shape, y_test_private.shape

score = model.evaluate(x_test_private, y_test_private, verbose=0)
print("PrivateTest üzerinde doğruluk başarımı:", score)

#farklı goruntuler ıle test ıslemı
x_test_private = test_images[5].reshape(-1, 48, 48, 1)

import cv2

!ls '/content/drive/My Drive/Evrisimli_Sinir_Aglari/Duygu_Tanima/images'

# en iyi ağırlıkları yükle
model.load_weights(root + 'data/face_model.h5')

image_path = root + '/content/drive/My Drive/Evrisimli_Sinir_Aglari/Duygu_Tanima/images/kemal_sunal.jpg' 
test_image_orjinal = image.load_img(image_path) #orjinal renkli goruntu 
 
test_image = image.load_img(image_path, target_size= (48, 48), grayscale = True)
test_data = iamge.img_to_array(test_image)
 
test_data = np.expand_dims(test_data, axis=0)
test_data = np.vstack([test_data])
results = model_best.predict(test_data, batch_size=1)
results

test_image=x_test

custom = model.predict(test_image.reshape(-1, 48, 48, 1))


#1
objects = ('kızgın', 'nefret', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')
y_pos = np.arange(len(objects))
    
plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')
plt.xticks(y_pos, objects)
plt.ylabel('yüzde')
plt.title('duygu')
plt.show()

#2
x = np.array(x, 'float32')
x = x.reshape([48, 48]);
plt.axis('off')
plt.gray()
plt.imshow(test_image.reshape(48,48))

plt.show()

